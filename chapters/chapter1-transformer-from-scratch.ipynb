{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer from Scratch\n",
        "\n",
        "A Transformer based on the architecture presented in Vaswani et al. (2017) Attention is all you need. I train it on the complete works of Shakespeare for 1 epoch.  \n",
        "  \n",
        "  \n",
        "Here's an example completion from the trained architecture (prompt in *italics*):  \n",
        "\n",
        "> *This is it!*_] This is a god of love, I fear the shot out. I  \n",
        "will be a pattern. Let him comply with the pikes. I am as the  \n",
        "fishes in the moon, the highest compulsion of his endowments are to  \n",
        "the trumpet, and besmear themselves to the Altar.\n",
        "\n",
        "> FIRST SOLDIER.  \n",
        "What is the matter that I am,  \n",
        "That I might not wish the Turk?\n",
        "\n",
        "> THIRD SOLDIER.  \n",
        "Faith, he did; and he doesâ€™t not?\n",
        "\n",
        "> FIRST CLOWN.  \n",
        "He does, sir.\n",
        "\n",
        "> FIRST CLOWN.  \n",
        "Ay, he is mad, sir, he was not mad and drinking to say he was  \n",
        "the hostess of a knave   \n",
        "  \n",
        "  For the project I only allowed myself to look at the Attention is All You Need paper except for two occasions: when I got confused about what $d_{model}$ meant and quickly checked the shape of the input for the attention layer at [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) and when I was writing the sampling function (which I copied with only small modifications from [here](https://github.com/ckkissane/deep_learning_curriculum/blob/master/solutions/1_Transformers.ipynb))"
      ],
      "metadata": {
        "id": "mAKvOh8WHl3c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lq5lVPe0EKh"
      },
      "source": [
        "# Set up\n",
        "\n",
        "Import some things we will need later and define the default device and types we will use for the model and data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peeK5qf7ztqr"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "factory_kwargs = {\"device\":\"cuda\", \"dtype\":torch.float}\n",
        "plt.rcParams[\"figure.figsize\"] = (8,6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eO7FVxt4hGd"
      },
      "source": [
        "# Creating the architecture\n",
        "Some notation I'll use:  \n",
        "* N = batch size  \n",
        "* T = sequence length  \n",
        "* V = vocabulary size  \n",
        "* D = dimension of the model\n",
        "* H = hidden dimmension in the feed-forward NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsQ-TlSKAMBv"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwBdbSnrucqI"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "  \"\"\"Maps sequences of integers from 0 to V (corresponding to a word in\n",
        "  the vocabulary) to a corresponding sequence of embedding vectors\"\"\"\n",
        "\n",
        "  def __init__(self, embed_dim, len_vocab, device=\"cpu\", dtype=torch.float):\n",
        "    super().__init__()\n",
        "    self.embed_mat = nn.Parameter(torch.empty(len_vocab, embed_dim,\n",
        "                                              device=device, dtype=dtype))\n",
        "    nn.init.xavier_uniform_(self.embed_mat)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T)\n",
        "    output: Tensor of shape (N, T, D)\"\"\"\n",
        "    return self.embed_mat[x, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDl6NgkFdQ51",
        "outputId": "abf96212-6945-4d2a-80f1-cd82450219aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 35, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "N, T, D, V = 9, 35, 8, 91\n",
        "x = torch.randint(0, V, (N, T), device=factory_kwargs[\"device\"])\n",
        "E = Embedding(D, V, **factory_kwargs)\n",
        "E(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfAgebTi4leK"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "  \"\"\"Adds a positional embedding matrix to the input. It also applies dropout\n",
        "  on the result using p=0.1\"\"\"\n",
        "\n",
        "  def __init__(self, embed_dim, max_len=200, device=\"cpu\", dtype=torch.float):\n",
        "    \"\"\"\n",
        "    input:\n",
        "    seq_len: Number of tokens in the input (assumming shorter inputs are padded\n",
        "    to get a consistent length)\n",
        "    embed_dim: Dimension of embedding space\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.n_param = 10000\n",
        "    assert embed_dim%2 == 0, \"embed_dim must be divisible by 2\"\n",
        "\n",
        "    self.embed_matrix = torch.zeros(max_len, embed_dim, device=device, dtype=dtype)\n",
        "    seq_pos = torch.arange(max_len, device=device)\n",
        "    embed_pos = torch.arange(embed_dim//2, device=device)\n",
        "    self.embed_matrix[:, ::2] = torch.sin(seq_pos.unsqueeze(1)/\n",
        "                                          (self.n_param**(2*embed_pos/embed_dim)))\n",
        "    self.embed_matrix[:, 1::2] = torch.cos(seq_pos.unsqueeze(1)/\n",
        "                                          (self.n_param**(2*embed_pos/embed_dim)))\n",
        "    self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T, D)\n",
        "    output: Returns the input plus the positional embedding\n",
        "    \"\"\"\n",
        "    return self.dropout(x + self.embed_matrix[:x.shape[-2]].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaM1_Mgp_9zI"
      },
      "source": [
        "Without dropout, we can compare the embedding to the results seen [here](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/#:~:text=To%20understand%20the%20above%20expression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxXiTXOC7AZh",
        "outputId": "dc936576-7c4b-472e-c429-ccccfc97cade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 35, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "N, T, D = 5, 35, 4\n",
        "x = torch.zeros(N, T, D, **factory_kwargs)\n",
        "PE = PositionalEmbedding(D, **factory_kwargs)\n",
        "PE(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "020ELwd2AQa-"
      },
      "source": [
        "## Attention Layer and Multihead Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFhSTQy2clA2"
      },
      "outputs": [],
      "source": [
        "def create_mask(seq_len, device=\"cpu\", dtype=torch.float):\n",
        "  \"\"\"Creates a triangular matrix which corresponds to a mask that stops the\n",
        "  prediction of a position from attending to previous positions\"\"\"\n",
        "  mask = (-1e10)*torch.ones(seq_len, seq_len, device=device, dtype=dtype)\n",
        "  mask = torch.triu(mask, 1)\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4at5V1LgAXp",
        "outputId": "f6eef89b-95ba-4c66-fde1-154274885761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "create_mask(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlnLFvg5AJjR"
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "  \"\"\"A single-headed attention layer\"\"\"\n",
        "\n",
        "  def __init__(self, d_model, v_dim, self_mask=True, q_dim=None,\n",
        "               device=\"cpu\", dtype=torch.float):\n",
        "    \"\"\"\n",
        "    input:\n",
        "    d_model: Model's dimension\n",
        "    v_dim: Dimension of output tensor\n",
        "    self_mask: if True, applies the diagonal mask constructed with the function\n",
        "    create_mask\n",
        "    q_dim: Number of queries (if None default to v_dim)\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__()\n",
        "    kwargs = {\"device\": device, \"dtype\": dtype}\n",
        "    if q_dim == None:\n",
        "      q_dim = v_dim\n",
        "    self.q_dim = q_dim\n",
        "    self.has_mask = self_mask\n",
        "    self.kwargs = kwargs\n",
        "\n",
        "    self.Wq = nn.Parameter(torch.empty(q_dim, d_model, **kwargs))\n",
        "    nn.init.xavier_uniform_(self.Wq)\n",
        "    self.bq = nn.Parameter(torch.zeros(q_dim, **kwargs))\n",
        "    self.Wk = nn.Parameter(torch.empty(q_dim, d_model, **kwargs))\n",
        "    nn.init.xavier_uniform_(self.Wk)\n",
        "    self.bk = nn.Parameter(torch.zeros(q_dim, **kwargs))\n",
        "    self.Wv = nn.Parameter(torch.empty(v_dim, d_model, **kwargs))\n",
        "    nn.init.xavier_uniform_(self.Wv)\n",
        "    self.bv = nn.Parameter(torch.zeros(v_dim, **kwargs))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T, D)\n",
        "    output: Tensor of shape (N, T, v_dim)\n",
        "    \"\"\"\n",
        "    Q = F.linear(x, self.Wq, self.bq)\n",
        "    K = F.linear(x, self.Wk, self.bk)\n",
        "    V = F.linear(x, self.Wv, self.bv)\n",
        "    similarity_score = (Q.matmul(K.transpose(-2,-1))/self.q_dim**0.5)\n",
        "    if self.has_mask:\n",
        "      mask = create_mask(similarity_score.shape[-1], **self.kwargs)\n",
        "      similarity_score = similarity_score + mask\n",
        "    return F.softmax(similarity_score, dim=-1).matmul(V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeqj3s1jIZmH",
        "outputId": "6075628f-f5b9-430c-a1ff-7abc9020bb7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "N, T, D, Vdim = 100, 8, 7, 9\n",
        "x = torch.ones(N, T, D, **factory_kwargs)\n",
        "\n",
        "AL = AttentionLayer(D, Vdim, **factory_kwargs)\n",
        "AL(x).shape # Result must be of size (N, T, Vdim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxW5cI5675Kd"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  \"\"\"A layer which runs n_heads self-attention heads in parallell and stacks their\n",
        "  output in a single tensor\"\"\"\n",
        "\n",
        "  def __init__(self, n_heads, d_model, self_mask=True, q_dim=None,\n",
        "               device=\"cpu\", dtype=torch.float):\n",
        "    super().__init__()\n",
        "    kwargs = {\"device\": device, \"dtype\": dtype}\n",
        "    assert d_model%n_heads == 0, \"Dimension of the model must be divisible by n_heads\"\n",
        "    v_dim = d_model//n_heads\n",
        "\n",
        "    self.Wo = nn.Parameter(torch.empty(d_model, n_heads*v_dim, **kwargs))\n",
        "    nn.init.xavier_uniform_(self.Wo)\n",
        "    self.heads = []\n",
        "    for _ in range(n_heads):\n",
        "      self.heads.append(AttentionLayer(d_model, v_dim, self_mask, q_dim, **kwargs))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T, D)\n",
        "    output: Tensor of shape (N, T, q_dim*n_heads)\"\"\"\n",
        "    head_results = []\n",
        "    for head in self.heads:\n",
        "      head_results.append(head(x))\n",
        "    return F.linear(torch.cat(head_results, dim=-1), self.Wo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ3P7KB_-d3_",
        "outputId": "f899fe9e-040b-4137-c867-f0807479f704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 15, 8])\n"
          ]
        }
      ],
      "source": [
        "N, T, D, n_heads = 100, 15, 8, 2\n",
        "x = torch.zeros(N, T, D, **factory_kwargs)\n",
        "\n",
        "MHA = MultiheadAttention(n_heads, D, **factory_kwargs)\n",
        "assert MHA(x).shape == x.shape # Input and output must be the same size for residual connection\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzLWhnZ5PLe"
      },
      "source": [
        "## Transformer Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp8U7usnU5RA"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  \"\"\"A layer normalization layer\"\"\"\n",
        "\n",
        "  def __init__(self, n_features, device=\"cpu\", dtype=torch.float):\n",
        "    super().__init__()\n",
        "    kwargs = {\"device\":device, \"dtype\": dtype}\n",
        "\n",
        "    self.beta = nn.Parameter(torch.zeros(n_features, **kwargs))\n",
        "    self.gamma = nn.Parameter(torch.ones(n_features, **kwargs))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T, D)\n",
        "    output: Tensor of shape (N, T, D)\n",
        "    \"\"\"\n",
        "    x = (x - x.mean(dim=-1, keepdim=True))/x.std(dim=-1, keepdim=True)\n",
        "    return self.gamma*x - self.beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEGY2Im1kmws"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  \"\"\"A Transformer block composed of a multi-headed self-attention layer followed by\n",
        "  a fully connected feed-forward network. In addition, each block is surrounded by\n",
        "  residual connections and feeds into a layer normalization component.\"\"\"\n",
        "\n",
        "  def __init__(self, n_heads, d_model, hidden_dim, self_mask=True, q_dim=None, device=\"cpu\",\n",
        "               dtype=torch.float):\n",
        "    super().__init__()\n",
        "    kwargs = {\"device\":device, \"dtype\": dtype}\n",
        "\n",
        "    self.attention = MultiheadAttention(n_heads, d_model, self_mask, q_dim, **kwargs)\n",
        "    self.batchnorm1 = LayerNorm(d_model, **kwargs)\n",
        "    self.linear1 = nn.Linear(d_model, hidden_dim, **kwargs)\n",
        "    self.linear2 = nn.Linear(hidden_dim, d_model, **kwargs)\n",
        "    self.batchnorm2 = LayerNorm(d_model, **kwargs)\n",
        "    self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T, D)\n",
        "    output: Tensor of shape (N, T, D)\n",
        "    \"\"\"\n",
        "    attention_out = self.dropout(self.attention(x))\n",
        "    x = self.batchnorm1(attention_out + x)\n",
        "    linear_out = self.dropout(F.relu(self.linear2(F.relu(self.linear1(x)))))\n",
        "    return self.batchnorm2(linear_out + x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aq2XwbAZuwN",
        "outputId": "bff6f384-2ad2-40b9-ebf2-31ff36011422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 15, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "N, T, D, n_heads, H = 100, 15, 40, 4, 30\n",
        "x = torch.zeros(N, T, D, **factory_kwargs)\n",
        "\n",
        "TB = TransformerBlock(n_heads, D, H, **factory_kwargs)\n",
        "TB(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-xgLrI9rtRX"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  \"\"\"Encoder only Transformer which starts with a layer of learned embedding\n",
        "  vectors followed by positional encoding, n_blocks Transformer Blocks and a\n",
        "  fully connected feed-forward network. A more detailed description is found in\n",
        "  Vaswani et al. (2017). Attention is all you need\"\"\"\n",
        "\n",
        "  def __init__(self, n_blocks, n_heads, d_model, hidden_dim, len_vocab,\n",
        "               q_dim=None, self_mask=True, device=\"cpu\", dtype=torch.float):\n",
        "\n",
        "    super().__init__()\n",
        "    self.kwargs = {\"device\": device, \"dtype\": dtype}\n",
        "\n",
        "    blocks = [TransformerBlock(n_heads, d_model, hidden_dim, self_mask, q_dim, **self.kwargs)\n",
        "              for _ in range(n_blocks)]\n",
        "\n",
        "    self.net = nn.Sequential(Embedding(d_model, len_vocab, **self.kwargs),\n",
        "                             PositionalEmbedding(d_model, **self.kwargs),\n",
        "                             *blocks,\n",
        "                              nn.Linear(d_model, len_vocab, **self.kwargs))\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    input: Tensor of shape (N, T) composed of integers from 0 to V\n",
        "    output: Tensor of shape (N, T, V)\n",
        "    \"\"\"\n",
        "    return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emwidTc2s_O9",
        "outputId": "a2aae05d-b278-4a7a-f3e6-b54558d5ded3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 35, 91])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "N, T, D = 3, 35, 8\n",
        "vocab, n_heads, n_blocks, H = 91, 2, 4, 30\n",
        "x = torch.randint(low=0, high=vocab, size=(N,T), device=factory_kwargs[\"device\"])\n",
        "\n",
        "T = Transformer(n_blocks, n_heads, D, hidden_dim=H,\n",
        "                len_vocab=vocab, **factory_kwargs)\n",
        "T(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "047SPrATeUQO"
      },
      "source": [
        "# Testing the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOTlBj5deUQW"
      },
      "source": [
        "## Defining helper classes and data functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjwtwgpXeUQW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from math import ceil\n",
        "import re\n",
        "\n",
        "def get_src_tgt(data):\n",
        "  \"\"\"Divide data sequences into a source (input to the model) and a target (the\n",
        "  sequence to be predicted). It assumes that data is a Tensor object or has a dim() function\"\"\"\n",
        "  return (data[:,:-1], data[:,1:])\n",
        "\n",
        "class Solver():\n",
        "\n",
        "  def __init__(self, model, data, optimizer, val_frac=0.2):\n",
        "    \"\"\"\n",
        "    A class with several tools to train and evaluate a model. As it trains it\n",
        "    stores the loss after every step and the training and validation accuracy\n",
        "    after every epoch\n",
        "\n",
        "    Input:\n",
        "    model: The model to be trained\n",
        "    data: A data object that can be indexed to obtain training and validation data\n",
        "    for the model\n",
        "    optimizer: An optimizer object that allows us to update the model parameters\n",
        "    val_frac: The fraction of data used for validation\n",
        "    \"\"\"\n",
        "    self.model = model\n",
        "    self.data = data\n",
        "    self.optimizer = optimizer\n",
        "    self.data_len = len(data)\n",
        "    self.train_data_len = int((1-val_frac)*self.data_len)\n",
        "    self.train_acc = []\n",
        "    self.val_acc = []\n",
        "    self.loss_hist = []\n",
        "    self.steps = 0\n",
        "\n",
        "    # We calculate train_acc only on 10% of the training set or 1000 examples\n",
        "    k = min(1000, self.train_data_len//10)\n",
        "    self.sample_train_idx = random.choices(range(self.data_len), k=k)\n",
        "    self.val_data_idx = slice(self.train_data_len, self.data_len)\n",
        "\n",
        "  def train(self, n_epochs=1, batch_size=128, print_every=1, warmup=None,\n",
        "            verbose=True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    n_epochs (float): Number of epochs to train for\n",
        "    batch_size: Batch size\n",
        "    print_every (float): If verbose=True, indicates the number of epochs in training\n",
        "    before printing the loss, training accuracy and validation accuracy\n",
        "    warmup: If not None, indicates the number of warmup steps for the learning\n",
        "    rate schedule used in _Attention is All You Need_\n",
        "    verbose: Whether to print updates on the performance of the model\n",
        "    \"\"\"\n",
        "\n",
        "    D = self.model.d_model\n",
        "    epoch_size = self.train_data_len\n",
        "    steps_per_epoch = epoch_size//batch_size\n",
        "    epoch = 0\n",
        "\n",
        "    if type(print_every) == float:\n",
        "      print_every_steps = ceil(print_every*steps_per_epoch)\n",
        "      print_every = 1\n",
        "    else:\n",
        "      print_every_steps = 1e20\n",
        "\n",
        "    i = 0\n",
        "    while self.steps < n_epochs*steps_per_epoch:\n",
        "      batch = self.data[i*batch_size:(i+1)*batch_size]\n",
        "      src, tgt = get_src_tgt(batch)\n",
        "      loss = self.train_step(src, tgt)\n",
        "      self.steps += 1\n",
        "      self.loss_hist.append(loss.item())\n",
        "\n",
        "      if warmup != None:\n",
        "        lr = (D**-.5)*min(self.steps**(-.5), self.steps*(warmup**(-1.5)))\n",
        "        for g in self.optimizer.param_groups:\n",
        "          g['lr'] = lr\n",
        "\n",
        "      if verbose and self.steps%print_every_steps == 0:\n",
        "        print(f\"Epoch {round(self.steps/steps_per_epoch, 3)}. Loss {round(loss.item(), 4)}\")\n",
        "        print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/10**9} GB\")\n",
        "\n",
        "      i += 1\n",
        "      # Restart the counter after every epoch\n",
        "      if i >= steps_per_epoch:\n",
        "        i = 0\n",
        "        epoch += 1\n",
        "\n",
        "        train_acc_e = self.eval(self.sample_train_idx)\n",
        "        self.train_acc.append(train_acc_e)\n",
        "        val_acc_e = self.eval(self.val_data_idx)\n",
        "        self.val_acc.append(val_acc_e)\n",
        "\n",
        "        if verbose and epoch%print_every == 0:\n",
        "          print(f\"Epoch {epoch}. Loss {round(loss.item(), 4)}\", end=\" // \")\n",
        "          print(f\"Train Acc: {train_acc_e}. Val Acc: {val_acc_e}\")\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def eval(self, eval_idx, print_sample=False, vocab=None):\n",
        "    \"\"\"\n",
        "    Returns the accuracy of the model on self.data[eval_idx].\n",
        "    If print_sample is True, it prints a comparison between a randomly chosen\n",
        "    target sequence and the prediction of the model.\n",
        "    If vocab is not None, it uses the vocab object to map the integers in the\n",
        "    predicted sequence to words.\n",
        "    \"\"\"\n",
        "    self.model.eval()\n",
        "\n",
        "    src, tgt = get_src_tgt(self.data[eval_idx])\n",
        "    logits = self.model(src)\n",
        "    logits_max, logits_pos = logits.max(dim=-1)\n",
        "    eval_acc = (logits_pos == tgt).to(torch.float).mean().item()\n",
        "    eval_acc = round(eval_acc, 3)\n",
        "\n",
        "    if print_sample:\n",
        "      i = random.choice(range(tgt.shape[0]))\n",
        "      if vocab != None:\n",
        "        print(f\"Original: \\n{''.join(vocab.lookup_tokens(tgt[i].tolist()))}\")\n",
        "        print(f\"Modelo: \\n{''.join(vocab.lookup_tokens(logits_pos[i].tolist()))}\")\n",
        "      else:\n",
        "        print(f\"Original: \\n{tgt[i]} \\nModelo: \\n{logits_pos[i]}\")\n",
        "\n",
        "    return eval_acc\n",
        "\n",
        "  # For the implementation of this function I took significant inspiration from\n",
        "  # https://github.com/ckkissane/deep_learning_curriculum/blob/master/solutions/1_Transformers.ipynb\n",
        "\n",
        "  def get_top_k(self, logits, k):\n",
        "    values, idx = torch.topk(logits, k, dim=-1)\n",
        "    out = torch.ones_like(logits)\n",
        "    out = out*(-float(\"inf\"))\n",
        "    out[:, idx] = logits[:, idx]\n",
        "    return out\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def sample(self, context, steps, T, top_k, temperature=1, vocab=None):\n",
        "    self.model.eval()\n",
        "    if vocab != None:\n",
        "      context = vocab.lookup_indices(re.split(r\"\\b\", context))\n",
        "      x = torch.Tensor(context).to(torch.long).to(self.model.kwargs[\"device\"])\n",
        "    else:\n",
        "      x = context\n",
        "\n",
        "    # I make sure that x has shape (N, T) even if N = 1\n",
        "    if x.dim() == 1:\n",
        "      x = x.unsqueeze(0)\n",
        "\n",
        "    for i in range(steps):\n",
        "      x_end = x if x.shape[1] < T else x[:, -T:]\n",
        "      logits = self.model(x_end)\n",
        "      logits = logits[:, -1, :]/temperature\n",
        "      logits = self.get_top_k(logits, top_k)\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "      comp_x = torch.multinomial(probs, num_samples=1)\n",
        "      x = torch.cat([x, comp_x], dim=1)\n",
        "\n",
        "    if vocab != None:\n",
        "      return [\"\".join(vocab.lookup_tokens(seq)) for seq in x.tolist()]\n",
        "    return x\n",
        "\n",
        "  # def export_predictions(self, file_name, eval_idx, vocab):\n",
        "  #   self.model.eval()\n",
        "  #   with torch.no_grad():\n",
        "  #     src, tgt = get_src_tgt(eval_idx)\n",
        "  #     out = self.model(src)\n",
        "  #     out_max, out_pos = out.max(dim=-1)\n",
        "\n",
        "  #   with open(file_name, \"w\") as file:\n",
        "  #     for i in range(out.shape[0]):\n",
        "  #       line1 = ''.join(vocab.lookup_tokens(tgt[i].tolist()))\n",
        "  #       line2 = ''.join(vocab.lookup_tokens(out_pos[i].tolist()))\n",
        "  #       file.write(\"Original: \" + re.sub(\"(<null>)*\", \"\", line1) + \"\\n\")\n",
        "  #       file.write(\"Modelo: \" + re.sub(\"(<null>)*\", \"\", line2) + \"\\n\")\n",
        "\n",
        "  def train_step(self, src, tgt):\n",
        "    \"\"\"Performs a training step on a mini-batch characterized by src and tgt\"\"\"\n",
        "    self.model.train()\n",
        "    self.optimizer.zero_grad()\n",
        "    logits = self.model(src)\n",
        "    if logits.shape[-1] != tgt.shape[-1]: # Because I don't follow the torch convention\n",
        "      logits = logits.transpose(-2, -1)\n",
        "    loss = F.cross_entropy(logits, tgt)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gen_data_simple_string(N, T, vocab_len, weight=None, device=\"cpu\", dtype=torch.int64):\n",
        "  \"\"\"Outputs N sequences of integers from 0 to vocab_len. Each sequence has length\n",
        "  T and is padded with 0s at the extremes. If weight is None each integer is just\n",
        "  as likely as any other\"\"\"\n",
        "  sequences = []\n",
        "  for _ in range(N):\n",
        "    seq = random.choices(range(1, vocab_len), weights=weight, k=T)\n",
        "    seq = torch.Tensor([0] + seq + [0]).to(torch.int64).to(device)\n",
        "    sequences.append(seq)\n",
        "  return torch.stack(sequences, dim=0)\n",
        "\n",
        "def gen_data_reverse_string(N, T, vocab_len, device=\"cpu\", dtype=torch.int64):\n",
        "  \"\"\"Outputs N symmetric sequences of integers from 0 to vocab_len.\n",
        "  Each sequence has length T and is padded with 0s at the extremes. Each integer\n",
        "  is just as likely as any other in the first half of the string\"\"\"\n",
        "  sequences = []\n",
        "  for _ in range(N):\n",
        "    seq = random.choices(range(1, vocab_len), k=(T-2)//2)\n",
        "    seq_reverse = seq.copy()\n",
        "    seq_reverse.reverse()\n",
        "    seq = torch.Tensor(tuple([0] + seq + seq_reverse + [0])).to(torch.int64).to(device)\n",
        "    sequences.append(seq)\n",
        "  return torch.stack(sequences, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9F0PZag2eUQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wnVsuJ3eUQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038d8656-2de4-4307-f186-ffcffb2a3e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 3, 4, 4, 2, 2, 0],\n",
            "        [0, 4, 2, 2, 4, 4, 0],\n",
            "        [0, 2, 2, 2, 3, 1, 0]])\n",
            "tensor([[0, 2, 2, 1, 1, 2, 2, 0],\n",
            "        [0, 2, 4, 4, 4, 4, 2, 0],\n",
            "        [0, 4, 3, 2, 2, 3, 4, 0]])\n"
          ]
        }
      ],
      "source": [
        "print(gen_data_simple_string(3, 5, 5))\n",
        "print(gen_data_reverse_string(3, 8, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahuGBIRseUQX"
      },
      "source": [
        "## Testing on simple sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVM2DileUQX"
      },
      "source": [
        "We check that the Transformer can learn the identity function. Given that we're not using masks it should be able to get perfect accuracy on the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfGQrjCkeUQY"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "\n",
        "N, T, D, V = 5000, 12, 64, 9\n",
        "n_blocks, n_heads, H = 2, 4, 100\n",
        "model1 = Transformer(n_blocks, n_heads, D, hidden_dim=D, len_vocab=V, self_mask=False,\n",
        "                       **factory_kwargs)\n",
        "\n",
        "weight = [random.random() for _ in range(V-1)]\n",
        "data = gen_data_simple_string(N, T, V, weight, **factory_kwargs)\n",
        "optimizer = optim.Adam(model1.parameters(), lr=1e-2)\n",
        "\n",
        "solver = Solver(model1, data, optimizer)\n",
        "solver.train(n_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlBbK4sleUQY"
      },
      "outputs": [],
      "source": [
        "test = slice(-5, -1)\n",
        "solver.eval(test, print_sample=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAJc4bTNeUQY"
      },
      "source": [
        "We check the mask works correctly by predicting symmetrical strings. The model should be able to predict only the second part of the string (by mirroring the first part). Absent overfitting, the model should on average have an accuracy of 60% for the parameters given (a little larger than 50% because it can correctly predict some tokens on the first part of the string by chance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgjPutm2eUQY"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "\n",
        "N, T, D, V = 5000, 12, 64, 9\n",
        "n_blocks, n_heads, H = 2, 4, 100\n",
        "\n",
        "model2 = Transformer(n_blocks, n_heads, D, hidden_dim=D, len_vocab=V,\n",
        "                       **factory_kwargs)\n",
        "\n",
        "data = gen_data_reverse_string(N, T, V, **factory_kwargs)\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-2)\n",
        "solver = Solver(model2, data, optimizer)\n",
        "solver.train(n_epochs=8)\n",
        "print(\"Max Possible Acc: \", round((T + T/(V-1) - 2/(V-1))/(2*(T-1)), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-BvQj6PeUQY"
      },
      "outputs": [],
      "source": [
        "test = slice(-5,-1)\n",
        "solver.eval(test, print_sample=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([0, 1, 2, 3, 4, 5]).to(factory_kwargs[\"device\"]).to(torch.long)\n",
        "solver.sample(x, steps=6, T=T, top_k=1)"
      ],
      "metadata": {
        "id": "vgWSo7FFeUQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G7zx8MnX4ml"
      },
      "source": [
        "# Imitating Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading text and parsing it"
      ],
      "metadata": {
        "id": "ep0exRebWlU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzJHS0HkYoIp"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the complete works of Shakespeare\n",
        "url = urlopen(\"https://www.gutenberg.org/files/100/100-0.txt\")\n",
        "book = url.read().decode('utf-8')\n",
        "start = re.search(\"From fairest\", book).start()\n",
        "book = book[start:] # Skip the file description\n",
        "tokenized = re.split(r\"\\b\", book)"
      ],
      "metadata": {
        "id": "7rujdbHfPkF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sFpf_jRbAvu",
        "outputId": "d5c7028b-65e6-45d3-f0fe-06d489e6bf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'From',\n",
              " ' ',\n",
              " 'fairest',\n",
              " ' ',\n",
              " 'creatures',\n",
              " ' ',\n",
              " 'we',\n",
              " ' ',\n",
              " 'desire',\n",
              " ' ',\n",
              " 'increase',\n",
              " ',\\r\\n',\n",
              " 'That',\n",
              " ' ',\n",
              " 'thereby',\n",
              " ' ',\n",
              " 'beauty',\n",
              " 'â€™',\n",
              " 's']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I only include tokens that appear at least twice because it makes the model train\n",
        "# like 40% faster. It amounts to cutting the number of tokens in half\n",
        "token_counter = OrderedDict(Counter(tokenized))\n",
        "vocab1 = vocab(token_counter, min_freq=2, specials=['<unk>', \"<null>\"])\n",
        "vocab1.set_default_index(vocab1[\"<unk>\"])\n",
        "print(\"Number of words in the the collected works: \", len(tokenized))\n",
        "print(\"Length of the vocabulary: \", len(vocab1))"
      ],
      "metadata": {
        "id": "-lqa2CoDc5NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e401503-a124-43ac-e487-e5cba2d5168e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in the the collected works:  1987529\n",
            "Length of the vocabulary:  20310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareDataset():\n",
        "  \"\"\"A dataset object which can be indexed to sample N sequences of length T from\n",
        "  vocab[text] (the integers that map through vocab to the original text)\n",
        "\n",
        "  When you index the Dataset object, the index is randomly mapped to another integer\n",
        "  from 0 to N, which is used to index T consecutive positions in vocab[text].\n",
        "  Additionally, each sequence is padded at both sides with vocab[\"null\"].\n",
        "\n",
        "  If N is not specified, the class uses the maximum number of different sequences\n",
        "  that it can create from the original text using the previous procedure\n",
        "  (roughly the number of tokens in the text) \"\"\"\n",
        "  def __init__(self, T, text=tokenized, vocab=vocab1, pad_token=\"<null>\",\n",
        "               N=None, dtype=torch.long, device=\"cpu\"):\n",
        "    self.seq_len = T\n",
        "    self.size = N\n",
        "    self.transform = lambda l: torch.Tensor(l).to(dtype).to(device)\n",
        "    self.corpus = self.transform(vocab.lookup_indices(text))\n",
        "    self.pad_token = self.transform([vocab[pad_token]])\n",
        "    self.shuffle_map = torch.randperm(len(self)).numpy()\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.size == None:\n",
        "      return len(self.corpus) - self.seq_len\n",
        "    else:\n",
        "      return self.size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if isinstance(idx, int):\n",
        "      idx_shuffle = self.shuffle_map[idx]\n",
        "      text = self.corpus[idx_shuffle:idx_shuffle+self.seq_len]\n",
        "      padded_text = torch.cat([self.pad_token, text, self.pad_token])\n",
        "      return padded_text\n",
        "    elif isinstance(idx, slice) or isinstance(idx, list):\n",
        "      data = []\n",
        "      for i in self.shuffle_map[idx]:\n",
        "        text = self.corpus[i:i+self.seq_len]\n",
        "        padded_text = torch.cat([self.pad_token, text, self.pad_token])\n",
        "        data.append(padded_text)\n",
        "      return torch.stack(data, dim=0)\n",
        "    else:\n",
        "      raise Exception(f\"__getitem__ not implemented for type {type(idx)}\")"
      ],
      "metadata": {
        "id": "hwt0jkhTXpEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning from Shakespeare"
      ],
      "metadata": {
        "id": "TDPrDMxJWsl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we train it for only in a small fraction of the data to make sure that the model starts reducing the loss. Sometimes the models gets stuck in a policy of predicting only blank spaces  "
      ],
      "metadata": {
        "id": "b3lXAqZRUivj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt5a4TXbJ5tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83d0fed-7762-49d2-ef3e-30c013bea39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0.01. Loss 5.6451\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.02. Loss 4.9987\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.03. Loss 4.9574\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.04. Loss 5.0297\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.05. Loss 4.9329\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.06. Loss 4.9827\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.07. Loss 4.1894\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.08. Loss 3.9962\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.09. Loss 4.0174\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Time training 0.1 epoch: 0:12:16.856011\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "data = ShakespeareDataset(T=64, device=factory_kwargs[\"device\"])\n",
        "N, T = len(data), 64\n",
        "\n",
        "D, V = 512, len(vocab1)\n",
        "n_blocks, n_heads, H = 6, 8, 2048\n",
        "\n",
        "model = Transformer(n_blocks, n_heads, D, hidden_dim=D, len_vocab=V,\n",
        "                       **factory_kwargs)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "solver = Solver(model, data, optimizer, val_frac=0.01)\n",
        "# The validation sample is small so it doesn't overflow the GPU's memory\n",
        "# (I haven't implemented evaluating the model in batches)\n",
        "\n",
        "start_time = datetime.now()\n",
        "solver.train(n_epochs=0.1, warmup=3000, print_every=0.01)\n",
        "end_time = datetime.now()\n",
        "print('Time training 0.1 epoch: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how it's going\n",
        "context = \"This is it!\"\n",
        "print(solver.sample(context, steps=200, T=T, top_k=5, vocab=vocab1)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3fTdhbBk2Kw",
        "outputId": "af581315-dac6-4089-b1d1-2ff8bfec7a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk>This is it!KING, I, I you and not,\r\n",
            "I you is a lord and a <unk>,\r\n",
            "    The lord with the <unk> of the the <unk>,\r\n",
            "And to I I I the the <unk> of the man the <unk>,\r\n",
            "And the <unk> of <unk> the his the man of of his his <unk> of\r\n",
            "That a man of his a the the man <unk> and\r\n",
            "Andâ€™s man of the man <unk> of of <unk>,\r\n",
            "To of the the the world to and of the the his man,\r\n",
            "    But. That to the a man of the man.\r\n",
            "\r\n",
            "d the lord.\r\n",
            "\r\n",
            "_.\r\n",
            "      The lord \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's train it for 1 epoch. I'd train it for longer, but it would involve policing Colab a lot to stop it from terminating the session.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "09m9Hx0Tr3UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solver.train(n_epochs=1, warmup=3000, print_every=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AXPlLbFj-Rb",
        "outputId": "7b08b690-2eb9-4293-df51-ec474560af49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0.2. Loss 3.4102\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.3. Loss 3.079\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.4. Loss 2.8036\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.5. Loss 2.668\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.6. Loss 2.5534\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.7. Loss 2.4556\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.8. Loss 2.39\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 0.901. Loss 2.3055\n",
            "Memory Allocated: 0.464793088 GB\n",
            "Epoch 1.001. Loss 2.2536\n",
            "Memory Allocated: 0.464793088 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"This is it!\"\n",
        "print(solver.sample(context, steps=200, T=T, top_k=5, vocab=vocab1)[0])"
      ],
      "metadata": {
        "id": "lYot5vZmzqS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c835eada-1aa9-49cb-e2d7-771c331f951b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk>This is it!_] This is a god of love, I fear the shot out. I\r\n",
            "will be a pattern. Let him comply with the pikes. I am as the\r\n",
            "fishes in the moon, the highest compulsion of his endowments are to\r\n",
            "the trumpet, and besmear themselves to the Altar.\r\n",
            "\r\n",
            "FIRST SOLDIER.\r\n",
            "What is the matter that I am,\r\n",
            "That I might not wish the Turk?\r\n",
            "\r\n",
            "THIRD SOLDIER.\r\n",
            "Faith, he did; and he doesâ€™t not?\r\n",
            "\r\n",
            "FIRST CLOWN.\r\n",
            "He does, sir.\r\n",
            "\r\n",
            "FIRST CLOWN.\r\n",
            "Ay, he is mad, sir, he was not mad and drinking to say he was\r\n",
            "the hostess of a knave \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(solver.loss_hist)\n",
        "plt.title(\"Loss history\")\n",
        "plt.xlabel(f\"Number of steps (1 epoch = {round(len(data)/128)} steps)\")\n",
        "_ = plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "XIoAJELu0J5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "e3f53e48-1122-4e93-9bba-8b807f442e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_eO7FVxt4hGd",
        "7hzLWhnZ5PLe",
        "047SPrATeUQO",
        "1G7zx8MnX4ml"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}